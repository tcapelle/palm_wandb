{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Palm and W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to setup Palm access and the corresponding VertexAI service account. \n",
    "\n",
    "See the documentation on how to get started using [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will  need to setup the GCP variables related to your project and zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"wandb-growth\"\n",
    "zone = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the quickstart example from the [PALM](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/quickstart-text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview(\n",
    "    temperature: float,\n",
    "    project_id: str = project_id,\n",
    "    location: str = zone,\n",
    ") -> str:\n",
    "    \"\"\"Ideation example with a Large Language Model\"\"\"\n",
    "\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    # TODO developer - override these parameters as needed:\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "        \"max_output_tokens\": 256,  # Token limit determines the maximum amount of text output.\n",
    "        \"top_p\": 0.8,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "        \"top_k\": 40,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(\n",
    "        \"Give me ten interview questions for the role of program manager.\",\n",
    "        **parameters,\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is your definition of a program manager?\n",
      "2. What are your key responsibilities as a program manager?\n",
      "3. What are your biggest challenges as a program manager?\n",
      "4. What are your biggest successes as a program manager?\n",
      "5. How do you measure the success of your programs?\n",
      "6. What are your leadership style and management style?\n",
      "7. How do you communicate with your team and stakeholders?\n",
      "8. How do you handle conflict and difficult situations?\n",
      "9. What are your goals for your career as a program manager?\n",
      "10. Why are you interested in this position?\n"
     ]
    }
   ],
   "source": [
    "res = interview(0.7)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Weights and Biases Tables to store our model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "queries = [\n",
    "    \"The planet earth is the \",\n",
    "    \"Implement a Python function to compute the Fibonacci numbers.\",\n",
    "    \"Write a Rust function that performs binary exponentiation.\",\n",
    "    \"How do I allocate memory in C?\",\n",
    "    \"What are the differences between Javascript and Python?\",\n",
    "    \"How do I find invalid indices in Postgres?\",\n",
    "    \"How can you implement a LRU (Least Recently Used) cache in Python?\",\n",
    "    \"What approach would you use to detect and prevent race conditions in a multithreaded application?\",\n",
    "    \"Can you explain how a decision tree algorithm works in machine learning?\",\n",
    "    \"How would you design a simple key-value store database from scratch?\",\n",
    "    \"How do you handle deadlock situations in concurrent programming?\",\n",
    "    \"What is the logic behind the A* search algorithm, and where is it used?\",\n",
    "    \"How can you design an efficient autocomplete system?\",\n",
    "    \"What approach would you take to design a secure session management system in a web application?\",\n",
    "    \"How would you handle collision in a hash table?\",\n",
    "    \"How can you implement a load balancer for a distributed system?\",\n",
    "    \"What is the fable involving a fox and grapes?\",\n",
    "    \"Write a story in the style of James Joyce about a trip to the Australian outback in 2083, to see robots in the beautiful desert.\",\n",
    "    \"Who does Harry turn into a balloon?\",\n",
    "    \"Write a tale about a time-traveling historian who's determined to witness the most significant events in human history.\",\n",
    "    \"Describe a day in the life of a secret agent who's also a full-time parent.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palm_call(\n",
    "    prompt: str,\n",
    "    temperature: float = 0.7,\n",
    "    max_output_tokens: int = 256,\n",
    "    top_p: float = 0.8,\n",
    "    top_k: int = 40,\n",
    "    project_id: str = project_id,\n",
    "    location: str = zone,\n",
    ") -> str:\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
    "        \"max_output_tokens\": max_output_tokens,  # Token limit determines the maximum amount of text output.\n",
    "        \"top_p\": top_p,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "        \"top_k\": top_k,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(\n",
    "        prompt,\n",
    "        **parameters,\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\"model\", \"time\", \"temperature\", \"max_output_tokens\", \"top_p\", \"top_k\", \"prompt\", \"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:52<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# let's define some configuration parameters\n",
    "config = dict(\n",
    "    temperature = 1.0,\n",
    "    max_output_tokens = 128,\n",
    "    top_p = 0.8,\n",
    "    top_k = 40,\n",
    ")\n",
    "\n",
    "# we iterate through the queries and call the model\n",
    "# adding the results to a table\n",
    "for q in tqdm(queries):\n",
    "    t0 = time.perf_counter()\n",
    "    res = palm_call(q, **config)\n",
    "    table.add_data(\n",
    "        \"text-bison@001\", \n",
    "        time.perf_counter() - t0, \n",
    "        config[\"temperature\"], \n",
    "        config[\"max_output_tokens\"], \n",
    "        config[\"top_p\"], \n",
    "        config[\"top_k\"], \n",
    "        q, \n",
    "        res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the table to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/palm/wandb/run-20230824_141909-1g0fwnzu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/wandb-palm/runs/1g0fwnzu' target=\"_blank\">rose-durian-4</a></strong> to <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">https://wandb.ai/capecape/wandb-palm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/wandb-palm/runs/1g0fwnzu' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/1g0fwnzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-durian-4</strong> at: <a href='https://wandb.ai/capecape/wandb-palm/runs/1g0fwnzu' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/1g0fwnzu</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_141909-1g0fwnzu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"wandb-palm\", config=config)\n",
    "\n",
    "wandb.log({\"palm_samples\": table})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Integration\n",
    "\n",
    "Weights and Biases supports Langchain, this means that you can use Palm in your Langchain application and benefit from the full suite of features that Weights and Biases offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time, wandb\n",
    "\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:scoayhx1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/palm/wandb/run-20230824_143151-rqy9ksjd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/wandb-palm/runs/rqy9ksjd' target=\"_blank\">silver-river-5</a></strong> to <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">https://wandb.ai/capecape/wandb-palm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/wandb-palm/runs/rqy9ksjd' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/rqy9ksjd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/capecape/wandb-palm/runs/rqy9ksjd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x286dccf10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"wandb-palm\", job_type=\"generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VertexAI(model=\"text-bison@001\", project=\"wandb-growth\", location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorldPickerTool(BaseTool):\n",
    "    name = \"pick_world\"\n",
    "    description = \"pick a virtual game world for your character or item naming\"\n",
    "    worlds = [\n",
    "                \"a mystic medieval island inhabited by intelligent and funny frogs\",\n",
    "                \"a modern anthill featuring a cyber-ant queen and her cyber-ant-workers\",\n",
    "                \"a digital world inhabited by friendly machine learning engineers\"\n",
    "            ]\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        time.sleep(1)\n",
    "        return random.choice(self.worlds)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"pick_world does not support async\")\n",
    "        \n",
    "class NameValidatorTool(BaseTool):\n",
    "    name = \"validate_name\"\n",
    "    description = \"validate if the name is properly generated\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        time.sleep(1)\n",
    "        if len(query) < 20:\n",
    "            return f\"This is a correct name: {query}\"\n",
    "        else:\n",
    "            return f\"This name is too long. It should be shorter than 20 characters.\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"validate_name does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [WorldPickerTool(), NameValidatorTool()]\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m pick a virtual game world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick a name for the hero\n",
      "Action: pick_name\n",
      "Action Input: None\u001b[0m\n",
      "Observation: pick_name is not a valid tool, try one of [pick_world, validate_name].\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick a name for the hero\n",
      "Action: pick_name\n",
      "Action Input: None\u001b[0m\n",
      "Observation: pick_name is not a valid tool, try one of [pick_world, validate_name].\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick a name for the hero\n",
      "Action: validate_name\n",
      "Action Input: \"Cyber-ant Queen\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis is a correct name: Cyber-ant Queen\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Cyber-ant Queen in a modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cyber-ant Queen in a modern anthill featuring a cyber-ant queen and her cyber-ant-workers'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Find a virtual game world for me and imagine the name of a hero in that world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma digital world inhabited by friendly machine learning engineers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma mystic medieval island inhabited by intelligent and funny frogs\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma digital world inhabited by friendly machine learning engineers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma digital world inhabited by friendly machine learning engineers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma digital world inhabited by friendly machine learning engineers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m pick_world\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Find a virtual game world for me and imagine the name of a jewel in that world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Let me pick a virtual game world first.\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I need to imagine the name of food in that world.\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Let me validate the name.\n",
      "Action: validate_name\n",
      "Action Input: cyber-ant-queen-cake\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis name is too long. It should be shorter than 20 characters.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Let me try another name.\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma mystic medieval island inhabited by intelligent and funny frogs\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Let me validate the name.\n",
      "Action: validate_name\n",
      "Action Input: frog-pie\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis is a correct name: frog-pie\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: frog-pie\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'frog-pie'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Find a virtual game world for me and imagine the name of food in that world.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-river-5</strong> at: <a href='https://wandb.ai/capecape/wandb-palm/runs/rqy9ksjd' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/rqy9ksjd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_143151-rqy9ksjd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting LLMs correctly to get the best performance\n",
    "\n",
    "Let's run some toy mathematical operations to see how LLMs work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions = [\n",
    "    \"5 + 3 * 2\",\n",
    "    \"10 / (4 - 2)\",\n",
    "    \"(7 + 3) * 2 - 5\",\n",
    "    \"2^3 + 4\",\n",
    "    \"8 / (2 + 2) - 1\",\n",
    "    \"3 * (5 - 2^2)\",\n",
    "    \"2 * 4 + (6 - 3)\",\n",
    "    \"10 / (2 + 2) + 1\",\n",
    "    \"(4 - 2) * (6 + 1)\",\n",
    "    \"8 / (2 + 2) + (3 - 1)\",\n",
    "    \"2^3 * 2 - 4\",\n",
    "    \"6 / (2 + 1) - 2\",\n",
    "    \"(3 + 2) * 4 - 6\",\n",
    "    \"9 / (3 + 2) + 1\",\n",
    "    \"(2^3 - 1) * (6 - 2)\",\n",
    "    \"12 / (4 + 2) - 1\",\n",
    "    \"2 * (3 + 4) - 5\",\n",
    "    \"15 / (3 + 2) - 1\",\n",
    "    \"(2^2 + 3) * (6 - 1)\",\n",
    "    \"18 / (6 + 2) - 2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try different prompts and ask the LLM to compute the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template1 = \"\"\"\n",
    "The following is the mathematical expression provided by the user.\n",
    "{question}\n",
    "\n",
    "Find the answer using the BODMAS return the answer as a float:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe following is the mathematical expression provided by the user.\\n5 + 3 * 2\\n\\nFind the answer using the BODMAS return the answer as a float:\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template1.format(question=expressions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_call(prompt_template1.format(question=expressions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to convert some operations to Python like `^` to `**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_expression(expr: str) -> str:\n",
    "    expr = expr.replace(\" \", \"\")\n",
    "    expr = expr.replace(\"[\", \"(\")\n",
    "    expr = expr.replace(\"]\", \")\")\n",
    "    expr = expr.replace(\"{\", \"(\")\n",
    "    expr = expr.replace(\"}\", \")\")\n",
    "    expr = expr.replace(\"^\", \"**\")\n",
    "    \n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr, math\n",
    "\n",
    "def evaluate_expr(expr: str) -> str:\n",
    "    local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
    "\n",
    "    try:\n",
    "        expr = correct_expression(expr)\n",
    "        output = str(\n",
    "            numexpr.evaluate(\n",
    "                expr.strip(),\n",
    "                global_dict={},  # restrict access to globals\n",
    "                local_dict=local_dict,  # add common mathematical functions\n",
    "            )\n",
    "        )\n",
    "        return float(output)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_expr(expressions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Table with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    temperature = 1.0,\n",
    "    max_output_tokens = 128,\n",
    "    top_p = 0.8,\n",
    "    top_k = 40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_palm(expressions, prompt_template, config):\n",
    "    \"Evaluate Palm on solving simple math expressions\"\n",
    "    accuracy = 0.\n",
    "    table = wandb.Table(columns = [\"prompt\", \"expression\", \"true_answer\", \n",
    "                                   \"pred_answer\", \"temperature\", \"max_output_tokens\", \n",
    "                                   \"top_p\", \"top_k\" ])\n",
    "    for exp in tqdm(expressions):\n",
    "        prompt = prompt_template.format(question=exp)\n",
    "        palm_answer = palm_call(\n",
    "            prompt,\n",
    "            temperature=config[\"temperature\"], \n",
    "            max_output_tokens=config[\"max_output_tokens\"], \n",
    "            top_p=config[\"top_p\"], \n",
    "            top_k=config[\"top_k\"])\n",
    "        try:\n",
    "            palm_answer = float(palm_answer)\n",
    "        except:\n",
    "            pass\n",
    "        true_answer = eval(exp)\n",
    "        table.add_data(\n",
    "            prompt,\n",
    "            exp, \n",
    "            true_answer, \n",
    "            palm_answer,\n",
    "            config[\"temperature\"], \n",
    "            config[\"max_output_tokens\"], \n",
    "            config[\"top_p\"], \n",
    "            config[\"top_k\"]\n",
    "        )\n",
    "        accuracy += palm_answer == true_answer\n",
    "        wandb.log({\"accuracy\": 100 * accuracy / len(expressions)})\n",
    "        wandb.log({\"calculated_expression\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yxjjgaka) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-cloud-14</strong> at: <a href='https://wandb.ai/capecape/wandb-palm/runs/yxjjgaka' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/yxjjgaka</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_160036-yxjjgaka/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yxjjgaka). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/palm/wandb/run-20230824_160201-klzn0ymv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/wandb-palm/runs/klzn0ymv' target=\"_blank\">polar-eon-15</a></strong> to <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">https://wandb.ai/capecape/wandb-palm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/wandb-palm/runs/klzn0ymv' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/klzn0ymv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/capecape/wandb-palm/runs/klzn0ymv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x28caa3010>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"wandb-palm\", job_type=\"msth_calculator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:35<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_palm(expressions, prompt_template1, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▃▃▅▅▅▅▆▆▆▆▆▆▆█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>25.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-eon-15</strong> at: <a href='https://wandb.ai/capecape/wandb-palm/runs/klzn0ymv' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/klzn0ymv</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_160201-klzn0ymv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a hard time solving this simple expression, let's improve the prompt and maybe play with the temperature parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = \"\"\"\n",
    "You are an expert mathematician. You can solve a given mathematical expression using the BODMAS rule.\n",
    "BODMAS stands for Bracket, Orders of Indices, Division, Multiplication, Addition and Subtraction. The computation should happen in that order.\n",
    "The dorder is as follows:\n",
    "B: Solve expressions inside brackets in this order -> small bracket followed by curly bracket and finally square bracket.\n",
    "O: Solve the indices such as roots, powers, etc.\n",
    "D: Divide the numbers which are given\n",
    "M: Multiply the numbers next\n",
    "A: Sum up the next numbers\n",
    "S: Subtract the numbers left in the end\n",
    "\n",
    "The following is the mathematical expression provided by the user.\n",
    "{question}\n",
    "\n",
    "Think about it step-by-step. Don't skip steps.\n",
    "\n",
    "When ready with the answer return the answer as a float:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use W&B Sweeps to explore the different combination of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = dict(\n",
    "    method=\"random\",\n",
    "    name=\"palm_sweep\",\n",
    "    metric={\"name\": \"accuracy\", \"goal\": \"maximize\"},\n",
    "    parameters=dict(\n",
    "        prompt_template={\"values\": [1,2]},\n",
    "        temperature={\"min\": 0.1, \"max\": 1.0},)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refactor the evaulation on a single function that depends on the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    temperature = 1.0,\n",
    "    max_output_tokens = 128,\n",
    "    top_p = 0.8,\n",
    "    top_k = 40,\n",
    "    prompt_template=1,\n",
    ")\n",
    "\n",
    "def sweep_func(config=config):\n",
    "    wandb.init(config=config)\n",
    "    config = wandb.config\n",
    "\n",
    "    if config.prompt_template == 1:\n",
    "        prompt_template = prompt_template1\n",
    "    else:\n",
    "        prompt_template = prompt_template2\n",
    "\n",
    "    evaluate_with_palm(expressions, prompt_template, config)\n",
    "\n",
    "    wandb.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tfx4ojp9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-haze-57</strong> at: <a href='https://wandb.ai/capecape/uncategorized/runs/tfx4ojp9' target=\"_blank\">https://wandb.ai/capecape/uncategorized/runs/tfx4ojp9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_160314-tfx4ojp9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tfx4ojp9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/palm/wandb/run-20230824_160343-3y89g86g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/uncategorized/runs/3y89g86g' target=\"_blank\">visionary-elevator-58</a></strong> to <a href='https://wandb.ai/capecape/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/uncategorized' target=\"_blank\">https://wandb.ai/capecape/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/uncategorized/runs/3y89g86g' target=\"_blank\">https://wandb.ai/capecape/uncategorized/runs/3y89g86g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:36<00:00,  1.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>5.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-elevator-58</strong> at: <a href='https://wandb.ai/capecape/uncategorized/runs/3y89g86g' target=\"_blank\">https://wandb.ai/capecape/uncategorized/runs/3y89g86g</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_160343-3y89g86g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9poww5en\n",
      "Sweep URL: https://wandb.ai/capecape/wandb-palm/sweeps/9poww5en\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"wandb-palm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kvo67oeu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprompt_template: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemperature: 0.41114374043542057\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/palm/wandb/run-20230824_160606-kvo67oeu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/wandb-palm/runs/kvo67oeu' target=\"_blank\">true-sweep-1</a></strong> to <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/capecape/wandb-palm/sweeps/9poww5en' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/sweeps/9poww5en</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/wandb-palm' target=\"_blank\">https://wandb.ai/capecape/wandb-palm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/capecape/wandb-palm/sweeps/9poww5en' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/sweeps/9poww5en</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/wandb-palm/runs/kvo67oeu' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/kvo67oeu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:37<00:00,  1.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>15.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-1</strong> at: <a href='https://wandb.ai/capecape/wandb-palm/runs/kvo67oeu' target=\"_blank\">https://wandb.ai/capecape/wandb-palm/runs/kvo67oeu</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230824_160606-kvo67oeu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id=sweep_id, function=sweep_func, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
